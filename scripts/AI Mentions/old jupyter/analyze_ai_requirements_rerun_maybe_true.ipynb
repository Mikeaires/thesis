{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78265d16",
   "metadata": {},
   "source": [
    "\n",
    "# Rerun True/Maybe (v6) and Compare\n",
    "\n",
    "This notebook builds rerun inputs for ads labeled **True** or **Maybe** in v6 (2018â€“2024), then compares rerun outputs to the original v6 results.\n",
    "\n",
    "Workflow:\n",
    "1) Load v6 results and collect True/Maybe ads.\n",
    "2) Build JSONL inputs (version label: `v6_rerun_tm`).\n",
    "3) Submit/wait/fetch with the existing batch CLI.\n",
    "4) Load rerun results and compare for label flips.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80937d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/Users/miguel/Documents/Master Thesis/Thesis/Results Datasets/ai_mentions/results/requirements'),\n",
       " PosixPath('/Users/miguel/Documents/Master Thesis/Thesis/Results Datasets/ai_mentions/prompts'),\n",
       " 'v6_rerun_tm')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import bz2\n",
    "import pandas as pd\n",
    "\n",
    "def find_root(marker='Results Datasets'):\n",
    "    p = Path.cwd().resolve()\n",
    "    for _ in range(6):\n",
    "        if (p/marker).exists():\n",
    "            return p\n",
    "        if p.parent == p:\n",
    "            break\n",
    "        p = p.parent\n",
    "    return Path.cwd().resolve()\n",
    "\n",
    "ROOT = find_root()\n",
    "RESULTS_DIR = ROOT / 'Results Datasets' / 'ai_mentions' / 'results' / 'requirements'\n",
    "TEXT_DIR = ROOT / 'Base Dataset' / 'Data' / '699_SJMM_Data_TextualData_v10.0' / 'sjmm_suf_ad_texts'\n",
    "PROMPTS_DIR = ROOT / 'Results Datasets' / 'ai_mentions' / 'prompts'\n",
    "VERSION_LABEL = 'v6_rerun_tm'\n",
    "YEARS = list(range(2018, 2025))\n",
    "\n",
    "RESULT_FILES_V6 = {y: RESULTS_DIR / f'ai_job_requirements_all_{y}_v6.json' for y in YEARS}\n",
    "RESULT_FILES_RERUN = {y: RESULTS_DIR / f'ai_job_requirements_all_{y}_{VERSION_LABEL}.json' for y in YEARS}\n",
    "TEXT_FILES = {y: TEXT_DIR / f'ads_sjmm_{y}.jsonl.bz2' for y in YEARS}\n",
    "RESULTS_DIR, PROMPTS_DIR, VERSION_LABEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ecb3362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ai_requirement\n",
       "False    26169\n",
       "Maybe      834\n",
       "True       300\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def load_results(path: Path, source: str) -> pd.DataFrame:\n",
    "    if not path.exists():\n",
    "        return pd.DataFrame()\n",
    "    obj = json.loads(path.read_text(encoding='utf-8'))\n",
    "    rows = []\n",
    "    for ys, ads in obj.items():\n",
    "        try:\n",
    "            year = int(ys)\n",
    "        except Exception:\n",
    "            continue\n",
    "        for ad_id, res in ads.items():\n",
    "            rows.append({\n",
    "                'year': year,\n",
    "                'ad_id': ad_id,\n",
    "                'ai_requirement': res.get('ai_requirement', 'False'),\n",
    "                'reason': res.get('reason') or '',\n",
    "                'keywords': res.get('keywords', []),\n",
    "                'source': source,\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_v6 = pd.concat([load_results(p, f'v6_{y}') for y, p in RESULT_FILES_V6.items()], ignore_index=True)\n",
    "df_v6['ai_requirement'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "628382d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ai_requirement</th>\n",
       "      <th>Maybe</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>118</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>119</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>100</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>142</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>117</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>119</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>119</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ai_requirement  Maybe  True\n",
       "year                       \n",
       "2018              118    26\n",
       "2019              119    44\n",
       "2020              100    36\n",
       "2021              142    53\n",
       "2022              117    50\n",
       "2023              119    40\n",
       "2024              119    51"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Collect True/Maybe by year\n",
    "target = df_v6[df_v6['ai_requirement'].isin(['True','Maybe'])]\n",
    "counts = target.groupby(['year','ai_requirement']).size().unstack(fill_value=0)\n",
    "counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0cb9616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2018: {'count': 144,\n",
       "  'jsonl': '/Users/miguel/Documents/Master Thesis/Thesis/Results Datasets/ai_mentions/batches/requirements/2018/v6_rerun_tm/ai_requirements_batch_all_2018_v6_rerun_tm_input.jsonl'},\n",
       " 2019: {'count': 163,\n",
       "  'jsonl': '/Users/miguel/Documents/Master Thesis/Thesis/Results Datasets/ai_mentions/batches/requirements/2019/v6_rerun_tm/ai_requirements_batch_all_2019_v6_rerun_tm_input.jsonl'},\n",
       " 2020: {'count': 136,\n",
       "  'jsonl': '/Users/miguel/Documents/Master Thesis/Thesis/Results Datasets/ai_mentions/batches/requirements/2020/v6_rerun_tm/ai_requirements_batch_all_2020_v6_rerun_tm_input.jsonl'},\n",
       " 2021: {'count': 195,\n",
       "  'jsonl': '/Users/miguel/Documents/Master Thesis/Thesis/Results Datasets/ai_mentions/batches/requirements/2021/v6_rerun_tm/ai_requirements_batch_all_2021_v6_rerun_tm_input.jsonl'},\n",
       " 2022: {'count': 167,\n",
       "  'jsonl': '/Users/miguel/Documents/Master Thesis/Thesis/Results Datasets/ai_mentions/batches/requirements/2022/v6_rerun_tm/ai_requirements_batch_all_2022_v6_rerun_tm_input.jsonl'},\n",
       " 2023: {'count': 159,\n",
       "  'jsonl': '/Users/miguel/Documents/Master Thesis/Thesis/Results Datasets/ai_mentions/batches/requirements/2023/v6_rerun_tm/ai_requirements_batch_all_2023_v6_rerun_tm_input.jsonl'},\n",
       " 2024: {'count': 170,\n",
       "  'jsonl': '/Users/miguel/Documents/Master Thesis/Thesis/Results Datasets/ai_mentions/batches/requirements/2024/v6_rerun_tm/ai_requirements_batch_all_2024_v6_rerun_tm_input.jsonl'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Build JSONL inputs for rerun (True/Maybe only)\n",
    "schema = {\n",
    "    'name': 'ai_requirement_simple',\n",
    "    'schema': {\n",
    "        'type': 'object',\n",
    "        'properties': {\n",
    "            'ai_requirement': {'type': 'string', 'enum': ['True','Maybe','False']},\n",
    "            'reason': {'type': 'string'},\n",
    "            'keywords': {'type': 'array', 'items': {'type': 'string'}}\n",
    "        },\n",
    "        'required': ['ai_requirement', 'reason', 'keywords'],\n",
    "        'additionalProperties': False\n",
    "    },\n",
    "    'strict': True,\n",
    "}\n",
    "\n",
    "prompt_path = PROMPTS_DIR / 'v6.txt'\n",
    "if prompt_path.exists():\n",
    "    system_prompt = prompt_path.read_text(encoding='utf-8')\n",
    "else:\n",
    "    system_prompt = 'Use the v6 prompt text here if prompt file is missing.'\n",
    "\n",
    "out_info = {}\n",
    "\n",
    "def write_jsonl_for_year(year: int, ids: set):\n",
    "    out_dir = ROOT / 'Results Datasets' / 'ai_mentions' / 'batches' / 'requirements' / str(year) / VERSION_LABEL\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    jsonl_path = out_dir / f'ai_requirements_batch_all_{year}_{VERSION_LABEL}_input.jsonl'\n",
    "    p = TEXT_FILES[year]\n",
    "    if not p.exists():\n",
    "        return 0, jsonl_path\n",
    "    written = 0\n",
    "    with bz2.open(p, 'rt', encoding='utf-8', errors='ignore') as fh, jsonl_path.open('w', encoding='utf-8') as out:\n",
    "        for line in fh:\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "            except Exception:\n",
    "                continue\n",
    "            ad = obj.get('adve_iden_adve')\n",
    "            if ad not in ids:\n",
    "                continue\n",
    "            txt = obj.get('adve_text_adve') or ''\n",
    "            if not isinstance(txt, str) or not txt:\n",
    "                continue\n",
    "            body = {\n",
    "                'model': 'gpt-5-mini',\n",
    "                'response_format': {'type': 'json_schema', 'json_schema': schema},\n",
    "                'messages': [\n",
    "                    {'role': 'system', 'content': system_prompt},\n",
    "                    {'role': 'user', 'content': json.dumps({'ad_id': ad, 'text': txt}, ensure_ascii=False)},\n",
    "                ],\n",
    "            }\n",
    "            rec = {\n",
    "                'custom_id': f\"{year}|{ad}\",\n",
    "                'method': 'POST',\n",
    "                'url': '/v1/chat/completions',\n",
    "                'body': body,\n",
    "            }\n",
    "            out.write(json.dumps(rec, ensure_ascii=False) + '')\n",
    "            written += 1\n",
    "    return written, jsonl_path\n",
    "\n",
    "for y in YEARS:\n",
    "    ids = set(target.loc[target['year']==y, 'ad_id'])\n",
    "    if not ids:\n",
    "        continue\n",
    "    n, pth = write_jsonl_for_year(y, ids)\n",
    "    out_info[y] = {'count': n, 'jsonl': str(pth)}\n",
    "out_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7be0b9",
   "metadata": {},
   "source": [
    "\n",
    "## Submit / Wait / Fetch\n",
    "Use the existing CLI script per year. Example (2018):\n",
    "```\n",
    "python scripts/AI\\ Mentions/validate_ai_requirements_batch.py submit --population all --start-year 2018 --end-year 2018 --agg-start-year 2018 --agg-end-year 2018 --version v6_rerun_tm --window 24h\n",
    "python scripts/AI\\ Mentions/validate_ai_requirements_batch.py wait   --population all --start-year 2018 --end-year 2018 --agg-start-year 2018 --agg-end-year 2018 --version v6_rerun_tm --poll 3\n",
    "python scripts/AI\\ Mentions/validate_ai_requirements_batch.py fetch  --population all --start-year 2018 --end-year 2018 --agg-start-year 2018 --agg-end-year 2018 --version v6_rerun_tm\n",
    "```\n",
    "Results will be written to `Results Datasets/ai_mentions/results/requirements/ai_job_requirements_all_<year>_v6_rerun_tm.json`.\n",
    "Raw outputs go to the corresponding `batches/requirements/<year>/v6_rerun_tm/` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e110fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerun files not found or empty; fetch rerun results first.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare v6 original vs rerun (once rerun files exist)\n",
    "\n",
    "dfs_rerun = []\n",
    "for y, p in RESULT_FILES_RERUN.items():\n",
    "    if p.exists():\n",
    "        df = load_results(p, f\"{VERSION_LABEL}_{y}\")\n",
    "        if not df.empty:\n",
    "            dfs_rerun.append(df)\n",
    "\n",
    "if not dfs_rerun:\n",
    "    print('Rerun files not found or empty; fetch rerun results first.')\n",
    "else:\n",
    "    df_rerun = pd.concat(dfs_rerun, ignore_index=True)\n",
    "    merged = (\n",
    "        df_v6[['year','ad_id','ai_requirement']]\n",
    "        .rename(columns={'ai_requirement':'orig_ai'})\n",
    "        .merge(\n",
    "            df_rerun[['year','ad_id','ai_requirement']]\n",
    "            .rename(columns={'ai_requirement':'rerun_ai'}),\n",
    "            on=['year','ad_id'], how='inner'\n",
    "        )\n",
    "    )\n",
    "    merged['agree'] = merged['orig_ai'] == merged['rerun_ai']\n",
    "    summary = merged.groupby(['orig_ai','rerun_ai']).size().reset_index(name='count')\n",
    "    flips = merged[~merged['agree']]\n",
    "    print('Agreement:', merged['agree'].mean())\n",
    "    print('Confusion:')\n",
    "    display(summary)\n",
    "    print('Sample flips:')\n",
    "    display(flips.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Parad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
