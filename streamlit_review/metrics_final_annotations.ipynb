{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Metrics for final_annotations_test\n",
        "\n",
        "Loads `final_annotations_test.json` and population truth from `annotations_full.json` (or the fallback in `old stuff`).\n",
        "Computes confusion and population-weighted metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import Counter, defaultdict\n",
        "from pathlib import Path\n",
        "\n",
        "# In notebooks, __file__ is not defined. Fall back to cwd.\n",
        "try:\n",
        "    BASE = Path(__file__).resolve().parent\n",
        "except NameError:\n",
        "    BASE = Path.cwd()\n",
        "DATA_DIR = BASE / \"data\"\n",
        "ANN_FILE = DATA_DIR / \"final_annotations_test.json\"\n",
        "POP_FILE = DATA_DIR / \"annotations_full.json\"\n",
        "POP_FILE_FALLBACK = DATA_DIR / \"old stuff\" / \"annotations_full.json\"\n",
        "\n",
        "labels = [\"True\", \"Maybe\", \"False\"]\n",
        "\n",
        "def load_population():\n",
        "    if POP_FILE.exists():\n",
        "        return json.loads(POP_FILE.read_text(encoding=\"utf-8\"))\n",
        "    return json.loads(POP_FILE_FALLBACK.read_text(encoding=\"utf-8\"))\n",
        "\n",
        "sample = json.loads(ANN_FILE.read_text(encoding=\"utf-8\"))\n",
        "pop = load_population()\n",
        "pop_truth = Counter(str(v.get(\"annotation\")).capitalize() for v in pop.values())\n",
        "\n",
        "rows = list(sample.values())\n",
        "truth_counts = Counter(r[\"annotation\"] for r in rows)\n",
        "pred_counts = Counter(r[\"v7\"] for r in rows)\n",
        "print(\"Truth counts:\", truth_counts)\n",
        "print(\"Pred counts:\", pred_counts)\n",
        "print(\"Population truth counts:\", pop_truth)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion (truth -> pred)\n",
        "conf = Counter((r[\"annotation\"], r[\"v7\"]) for r in rows)\n",
        "print(\"Confusion (truth->pred):\")\n",
        "for t in labels:\n",
        "    row = {p: conf[(t, p)] for p in labels if conf[(t, p)]}\n",
        "    print(t, row)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Population-weighted metrics (one-vs-rest)\n",
        "weights = {t: pop_truth[t] / truth_counts[t] for t in truth_counts}\n",
        "TP = Counter(); FP = Counter(); FN = Counter(); TN = Counter()\n",
        "for r in rows:\n",
        "    t = r[\"annotation\"]\n",
        "    p = r[\"v7\"]\n",
        "    w = weights[t]\n",
        "    for lab in labels:\n",
        "        if p == lab and t == lab:\n",
        "            TP[lab] += w\n",
        "        elif p == lab and t != lab:\n",
        "            FP[lab] += w\n",
        "        elif p != lab and t == lab:\n",
        "            FN[lab] += w\n",
        "        else:\n",
        "            TN[lab] += w\n",
        "\n",
        "print(\"Weighted metrics:\")\n",
        "for lab in labels:\n",
        "    prec = TP[lab] / (TP[lab] + FP[lab]) if (TP[lab] + FP[lab]) else 0\n",
        "    rec = TP[lab] / (TP[lab] + FN[lab]) if (TP[lab] + FN[lab]) else 0\n",
        "    fpr = FP[lab] / (FP[lab] + TN[lab]) if (FP[lab] + TN[lab]) else 0\n",
        "    spec = TN[lab] / (FP[lab] + TN[lab]) if (FP[lab] + TN[lab]) else 0\n",
        "    print(f\"{lab}: Prec {prec:.3f}, Rec {rec:.3f}, FPR {fpr:.3f}, Spec {spec:.3f} | \"\n",
        "          f\"TP {TP[lab]:.3f}, FP {FP[lab]:.3f}, FN {FN[lab]:.3f}, TN {TN[lab]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bucket distributions\n",
        "def bucket_for_year(year: int) -> str | None:\n",
        "    if 2010 <= year <= 2014:\n",
        "        return \"early\"\n",
        "    if 2015 <= year <= 2019:\n",
        "        return \"mid\"\n",
        "    if 2020 <= year <= 2024:\n",
        "        return \"late\"\n",
        "    return None\n",
        "\n",
        "bucket_counts = Counter(bucket_for_year(r[\"year\"]) for r in rows)\n",
        "print(\"Bucket counts:\", bucket_counts)\n",
        "\n",
        "# Bucket % within each pred class\n",
        "class_bucket = defaultdict(Counter)\n",
        "for r in rows:\n",
        "    b = bucket_for_year(r[\"year\"])\n",
        "    class_bucket[r[\"v7\"]][b] += 1\n",
        "print(\"\\nBucket % within each pred class:\")\n",
        "for p in labels:\n",
        "    tot = sum(class_bucket[p].values())\n",
        "    print(p, {b: f\"{class_bucket[p][b]/tot*100:.1f}%\" for b in [\"early\", \"mid\", \"late\"]})\n",
        "\n",
        "# Bucket % within each confusion cell\n",
        "cell_bucket = defaultdict(Counter)\n",
        "cell_tot = Counter()\n",
        "for r in rows:\n",
        "    b = bucket_for_year(r[\"year\"])\n",
        "    key = (r[\"annotation\"], r[\"v7\"])\n",
        "    cell_bucket[key][b] += 1\n",
        "    cell_tot[key] += 1\n",
        "print(\"\\nBucket % within each truth->pred cell:\")\n",
        "for t in labels:\n",
        "    for p in labels:\n",
        "        k = (t, p)\n",
        "        tot = cell_tot[k]\n",
        "        if tot == 0:\n",
        "            continue\n",
        "        print(f\"{t}->{p}\", {b: f\"{cell_bucket[k][b]/tot*100:.1f}%\" for b in [\"early\", \"mid\", \"late\"]})\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
